const express = require('express');
const cors = require('cors');
const bodyParser = require('body-parser');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const OpenAI = require('openai');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3001;

// Initialize AI services
const genAI = process.env.GEMINI_API_KEY 
  ? new GoogleGenerativeAI(process.env.GEMINI_API_KEY) 
  : null;

const openai = process.env.OPENAI_API_KEY 
  ? new OpenAI({ apiKey: process.env.OPENAI_API_KEY }) 
  : null;

// Middleware
const corsOrigins = process.env.CORS_ORIGINS 
  ? process.env.CORS_ORIGINS.split(',').map(origin => origin.trim())
  : ['http://localhost:8081', 'exp://localhost:8081'];

app.use(cors({
  origin: corsOrigins,
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization']
}));

app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: true }));

// Health check
app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'OK', 
    message: 'AI Studio Backend is running',
    services: {
      gemini: genAI ? 'Configured âœ“' : 'Not configured âœ—',
      openai: openai ? 'Configured âœ“' : 'Not configured âœ—'
    }
  });
});

// ============================================
// AI CHAT ENDPOINT (Gemini)
// ============================================
app.post('/api/ai/chat', async (req, res) => {
  const { message, conversationHistory = [] } = req.body;

  if (!message) {
    return res.status(400).json({ error: 'Message is required' });
  }

  if (!genAI) {
    return res.status(500).json({ error: 'Gemini API not configured. Please set GEMINI_API_KEY in .env file' });
  }

  try {
    // Use gemini-2.0-flash-exp (free tier, 200 tokens/day)
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    // Build conversation context
    let conversationContext = '';
    if (conversationHistory.length > 0) {
      conversationHistory.forEach((msg) => {
        conversationContext += `${msg.role === 'user' ? 'User' : 'Assistant'}: ${msg.content}\n\n`;
      });
    }
    conversationContext += `User: ${message}\n\nAssistant:`;

    // Generate response
    const result = await model.generateContent(conversationContext);
    const response = await result.response;
    const aiResponse = response.text();

    res.json({
      response: aiResponse,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('AI Chat Error:', error);
    res.status(500).json({ 
      error: 'Failed to process AI request', 
      message: error.message 
    });
  }
});

// ============================================
// IMAGE GENERATION ENDPOINT (DALL-E)
// ============================================
app.post('/api/ai/image', async (req, res) => {
  const { prompt, size = '1024x1024', quality = 'standard', n = 1 } = req.body;

  if (!prompt) {
    return res.status(400).json({ error: 'Prompt is required' });
  }

  if (!openai) {
    return res.status(500).json({ error: 'OpenAI API not configured. Please set OPENAI_API_KEY in .env file' });
  }

  try {
    // Validate size
    const validSizes = ['256x256', '512x512', '1024x1024', '1792x1024', '1024x1792'];
    if (!validSizes.includes(size)) {
      return res.status(400).json({ error: `Invalid size. Must be one of: ${validSizes.join(', ')}` });
    }

    // Validate quality (only for 1024x1024)
    const validQuality = ['standard', 'hd'];
    if (size === '1024x1024' && !validQuality.includes(quality)) {
      return res.status(400).json({ error: `Invalid quality. Must be one of: ${validQuality.join(', ')}` });
    }

    // Generate image using DALL-E 3
    const response = await openai.images.generate({
      model: 'dall-e-3',
      prompt: prompt,
      n: 1, // DALL-E 3 only supports n=1
      size: size,
      quality: size === '1024x1024' ? quality : undefined,
      response_format: 'url'
    });

    const imageUrl = response.data[0].url;

    res.json({
      imageUrl: imageUrl,
      prompt: prompt,
      size: size,
      quality: quality,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('Image Generation Error:', error);
    res.status(500).json({ 
      error: 'Failed to generate image', 
      message: error.message 
    });
  }
});

// ============================================
// CREATOR - BLOG GENERATION (Gemini)
// ============================================
app.post('/api/ai/blog', async (req, res) => {
  const { topic, tone = 'professional', length = 'medium', style = 'article' } = req.body;

  if (!topic) {
    return res.status(400).json({ error: 'Topic is required' });
  }

  if (!genAI) {
    return res.status(500).json({ error: 'Gemini API not configured' });
  }

  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    const prompt = `Write a ${length} ${style} blog post about "${topic}" in a ${tone} tone. 
    Include an engaging title, introduction, main content with key points, and a conclusion. 
    Make it informative and well-structured.`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const content = response.text();

    res.json({
      content: content,
      topic: topic,
      tone: tone,
      length: length,
      style: style,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('Blog Generation Error:', error);
    res.status(500).json({ 
      error: 'Failed to generate blog content', 
      message: error.message 
    });
  }
});

// ============================================
// CREATOR - SOCIAL MEDIA CONTENT (Gemini)
// ============================================
app.post('/api/ai/social', async (req, res) => {
  const { topic, platform = 'general', tone = 'engaging', hashtags = true } = req.body;

  if (!topic) {
    return res.status(400).json({ error: 'Topic is required' });
  }

  if (!genAI) {
    return res.status(500).json({ error: 'Gemini API not configured' });
  }

  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    const platformGuidelines = {
      twitter: 'Keep it under 280 characters, use 1-2 hashtags',
      instagram: 'Write engaging caption with 5-10 relevant hashtags',
      linkedin: 'Professional tone, 1-3 hashtags, longer form content',
      facebook: 'Friendly and engaging, 2-5 hashtags',
      general: 'Engaging social media post with relevant hashtags'
    };

    const guidelines = platformGuidelines[platform] || platformGuidelines.general;

    const prompt = `Create a ${tone} social media post for ${platform} about "${topic}". 
    ${guidelines}. 
    ${hashtags ? 'Include relevant hashtags at the end.' : 'Do not include hashtags.'}
    Make it engaging and shareable.`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const content = response.text();

    res.json({
      content: content,
      topic: topic,
      platform: platform,
      tone: tone,
      hashtags: hashtags,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('Social Content Generation Error:', error);
    res.status(500).json({ 
      error: 'Failed to generate social content', 
      message: error.message 
    });
  }
});

// ============================================
// CREATOR - PROMPT GENERATION (Gemini)
// ============================================
app.post('/api/ai/prompt', async (req, res) => {
  const { purpose, context, style = 'detailed' } = req.body;

  if (!purpose) {
    return res.status(400).json({ error: 'Purpose is required' });
  }

  if (!genAI) {
    return res.status(500).json({ error: 'Gemini API not configured' });
  }

  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    const prompt = `Generate a ${style} AI prompt for the following purpose: "${purpose}"
    ${context ? `Context: ${context}` : ''}
    
    Create a well-structured prompt that will help an AI generate high-quality content. 
    Include clear instructions, desired output format, and any specific requirements.`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const generatedPrompt = response.text();

    res.json({
      prompt: generatedPrompt,
      purpose: purpose,
      context: context || null,
      style: style,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('Prompt Generation Error:', error);
    res.status(500).json({ 
      error: 'Failed to generate prompt', 
      message: error.message 
    });
  }
});

// Error handling middleware
app.use((err, req, res, next) => {
  console.error(err.stack);
  res.status(500).json({ error: 'Something went wrong!', message: err.message });
});

// 404 handler
app.use((req, res) => {
  res.status(404).json({ error: 'Endpoint not found' });
});

// Start server
app.listen(PORT, '0.0.0.0', () => {
  console.log(`ðŸš€ AI Studio Backend is running on port ${PORT}`);
  console.log(`ðŸŒ Server accessible on all interfaces (0.0.0.0:${PORT})`);
  console.log(`ðŸ¤– Gemini AI: ${genAI ? 'Configured âœ“' : 'Not configured âœ—'}`);
  console.log(`ðŸŽ¨ OpenAI (DALL-E): ${openai ? 'Configured âœ“' : 'Not configured âœ—'}`);
  console.log(`\nðŸ“‹ Available endpoints:`);
  console.log(`   GET  /api/health - Health check`);
  console.log(`   POST /api/ai/chat - AI chat messaging (Gemini)`);
  console.log(`   POST /api/ai/image - Image generation (DALL-E)`);
  console.log(`   POST /api/ai/blog - Blog content generation (Gemini)`);
  console.log(`   POST /api/ai/social - Social media content (Gemini)`);
  console.log(`   POST /api/ai/prompt - Prompt generation (Gemini)`);
});

// Graceful shutdown
process.on('SIGINT', () => {
  console.log('\nðŸ›‘ Shutting down AI Studio Backend...');
  process.exit(0);
});

